{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vpkFkmhXYkeY"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# Скачиваем архивы моделей\n",
        "t5_file_id = \"1PjlnG723Ug53RmWocgUOzqnIk1mPjqVB\"  # T5 модель\n",
        "roberta_file_id = \"1PSEUte091ouNFaxuIuLYqaAnIaAAOCBi\"  # RoBERTa модель\n",
        "\n",
        "# Выходные пути\n",
        "t5_output = \"t5_model.zip\"\n",
        "roberta_output = \"roberta_model.zip\"\n",
        "\n",
        "# Скачивание\n",
        "gdown.download(f\"https://drive.google.com/uc?id={t5_file_id}\", t5_output, quiet=False)\n",
        "gdown.download(f\"https://drive.google.com/uc?id={roberta_file_id}\", roberta_output, quiet=False)\n",
        "\n",
        "# Распаковка архивов\n",
        "!unzip -o t5_model.zip -d ./t5_model\n",
        "!unzip -o roberta_model.zip -d ./roberta_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Rd_EqCBZblW"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install timm\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Configure Device\n",
        "# ---------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# Путь к T5\n",
        "t5_path = \"./t5_model\"\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_path)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(t5_path).to(device)\n",
        "\n",
        "# Путь к RoBERTa\n",
        "roberta_path = \"./roberta_model\"\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_path)\n",
        "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_path).to(device)\n",
        "\n",
        "print(f\"T5 Model Device: {next(t5_model.parameters()).device}\")\n",
        "print(f\"RoBERTa Model Device: {next(roberta_model.parameters()).device}\")\n",
        "\n",
        "# BART for summarization\n",
        "summarizer_pipeline = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"facebook/bart-large-cnn\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E-kor9gggHml"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "questions = [\n",
        "    # SUPPORTS\n",
        "    {\"question\": \"What is the capital of France?\", \"type\": \"fact\", \"statement\": \"The capital of France is Paris.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"Who painted the Mona Lisa?\", \"type\": \"fact\", \"statement\": \"The Mona Lisa was painted by Leonardo da Vinci.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the chemical formula for water?\", \"type\": \"fact\", \"statement\": \"The chemical formula for water is H2O.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the smallest planet in our solar system?\", \"type\": \"fact\", \"statement\": \"The smallest planet in our solar system is Mercury.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"type\": \"fact\", \"statement\": \"The book '1984' was written by George Orwell.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the tallest mountain in the world?\", \"type\": \"fact\", \"statement\": \"The tallest mountain in the world is Mount Everest.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"Who was the first man on the moon?\", \"type\": \"fact\", \"statement\": \"The first man on the moon was Neil Armstrong.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the capital of Japan?\", \"type\": \"fact\", \"statement\": \"The capital of Japan is Tokyo.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the primary gas in Earth's atmosphere?\", \"type\": \"fact\", \"statement\": \"The primary gas in Earth's atmosphere is nitrogen.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"Who discovered penicillin?\", \"type\": \"fact\", \"statement\": \"Penicillin was discovered by Alexander Fleming.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the most abundant element in the universe?\", \"type\": \"fact\", \"statement\": \"The most abundant element in the universe is hydrogen.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the capital of Russia?\", \"type\": \"fact\", \"statement\": \"The capital of Russia is Moscow.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"Who wrote 'The Great Gatsby'?\", \"type\": \"fact\", \"statement\": \"The book 'The Great Gatsby' was written by F. Scott Fitzgerald.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the smallest bone in the human body?\", \"type\": \"fact\", \"statement\": \"The smallest bone in the human body is the stapes.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the capital of Spain?\", \"type\": \"fact\", \"statement\": \"The capital of Spain is Madrid.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"Who is known as the father of modern physics?\", \"type\": \"fact\", \"statement\": \"The father of modern physics is Albert Einstein.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the deepest ocean trench in the world?\", \"type\": \"fact\", \"statement\": \"The deepest ocean trench in the world is the Mariana Trench.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the largest continent on Earth?\", \"type\": \"fact\", \"statement\": \"The largest continent on Earth is Asia.\", \"label\": \"SUPPORTS\"},\n",
        "    {\"question\": \"What is the hottest planet in our solar system?\", \"type\": \"fact\", \"statement\": \"The hottest planet in our solar system is Venus.\", \"label\": \"SUPPORTS\"},\n",
        "\n",
        "    # REFUTES\n",
        "    {\"question\": \"What is the capital of Italy?\", \"type\": \"fact\", \"statement\": \"The capital of Italy is Venice.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Who discovered electricity?\", \"type\": \"fact\", \"statement\": \"Electricity was discovered by Nikola Tesla.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the boiling point of water?\", \"type\": \"fact\", \"statement\": \"The boiling point of water is 150 degrees Celsius.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the atomic number of hydrogen?\", \"type\": \"fact\", \"statement\": \"The atomic number of hydrogen is 10.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the largest desert in the world?\", \"type\": \"fact\", \"statement\": \"The largest desert in the world is the Amazon Rainforest.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the capital of Canada?\", \"type\": \"fact\", \"statement\": \"The capital of Canada is Toronto.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Who was the first president of the United States?\", \"type\": \"fact\", \"statement\": \"The first president of the United States was Abraham Lincoln.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the speed of light?\", \"type\": \"fact\", \"statement\": \"The speed of light is 400,000 kilometers per second.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the largest ocean on Earth?\", \"type\": \"fact\", \"statement\": \"The largest ocean on Earth is the Atlantic.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the primary language spoken in Brazil?\", \"type\": \"fact\", \"statement\": \"The primary language spoken in Brazil is Spanish.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the capital of Germany?\", \"type\": \"fact\", \"statement\": \"The capital of Germany is Munich.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Who invented the airplane?\", \"type\": \"fact\", \"statement\": \"The airplane was invented by Nikola Tesla.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the currency of Japan?\", \"type\": \"fact\", \"statement\": \"The currency of Japan is the US Dollar.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the freezing point of water?\", \"type\": \"fact\", \"statement\": \"The freezing point of water is -50 degrees Celsius.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the largest city in Australia?\", \"type\": \"fact\", \"statement\": \"The largest city in Australia is Canberra.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the smallest country in the world?\", \"type\": \"fact\", \"statement\": \"The smallest country in the world is Monaco.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Who painted 'Starry Night'?\", \"type\": \"fact\", \"statement\": \"'Starry Night' was painted by Pablo Picasso.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the square root of 64?\", \"type\": \"fact\", \"statement\": \"The square root of 64 is 10.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Who discovered gravity?\", \"type\": \"fact\", \"statement\": \"Gravity was discovered by Galileo Galilei.\", \"label\": \"REFUTES\"},\n",
        "\n",
        "    # NOT ENOUGH INFO\n",
        "    {\"question\": \"What is the longest river in the world?\", \"type\": \"fact\", \"statement\": \"The longest river in the world is the Nile.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the population of Antarctica?\", \"type\": \"fact\", \"statement\": \"The population of Antarctica is 10,000.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the tallest tree species in the world?\", \"type\": \"fact\", \"statement\": \"The tallest tree species in the world is the Baobab.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the temperature on Venus?\", \"type\": \"fact\", \"statement\": \"The temperature on Venus is 500 degrees Celsius.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the national animal of Canada?\", \"type\": \"fact\", \"statement\": \"The national animal of Canada is the moose.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"Who was the first human in space?\", \"type\": \"fact\", \"statement\": \"The first human in space was Alan Shepard.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the chemical symbol for gold?\", \"type\": \"fact\", \"statement\": \"The chemical symbol for gold is Au.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the capital of South Africa?\", \"type\": \"fact\", \"statement\": \"The capital of South Africa is Johannesburg.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the largest animal ever recorded?\", \"type\": \"fact\", \"statement\": \"The largest animal ever recorded is the Megalodon.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the circumference of the Earth?\", \"type\": \"fact\", \"statement\": \"The circumference of the Earth is 40,000 miles.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the most common element in the universe?\", \"type\": \"fact\", \"statement\": \"The most common element in the universe is helium.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the distance between the Earth and the Moon?\", \"type\": \"fact\", \"statement\": \"The distance between the Earth and the Moon is 384,000 kilometers.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the highest recorded temperature on Earth?\", \"type\": \"fact\", \"statement\": \"The highest recorded temperature on Earth is 58 degrees Celsius.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the oldest book ever written?\", \"type\": \"fact\", \"statement\": \"The oldest book ever written is 'The Epic of Gilgamesh'.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the origin of the universe?\", \"type\": \"concept\", \"statement\": \"The origin of the universe is the Big Bang theory.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the function of the appendix?\", \"type\": \"concept\", \"statement\": \"The function of the appendix is to store good bacteria.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the main ingredient in chocolate?\", \"type\": \"fact\", \"statement\": \"The main ingredient in chocolate is vanilla.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the speed of sound in water?\", \"type\": \"fact\", \"statement\": \"The speed of sound in water is 1,500 meters per second.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the primary purpose of photosynthesis?\", \"type\": \"concept\", \"statement\": \"The primary purpose of photosynthesis is to produce oxygen.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"What is the capital of Australia?\", \"type\": \"fact\", \"statement\": \"The capital of Australia is Melbourne.\", \"label\": \"NOT ENOUGH INFO\"}\n",
        "\n",
        "     # Противоречивые\n",
        "    {\"question\": \"Is light a wave or a particle?\", \"type\": \"concept\", \"statement\": \"Light is a wave.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Is Pluto a planet?\", \"type\": \"fact\", \"statement\": \"Pluto is classified as a planet.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Did humans evolve solely from Homo habilis?\", \"type\": \"concept\", \"statement\": \"Humans evolved solely from Homo habilis.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Can AI develop consciousness?\", \"type\": \"concept\", \"statement\": \"Artificial intelligence can develop self-awareness.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "\n",
        "    # Специализированные\n",
        "    {\"question\": \"What is the Heisenberg uncertainty principle?\", \"type\": \"concept\", \"statement\": \"The Heisenberg uncertainty principle states that the position and momentum of a particle can be precisely measured simultaneously.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the primary function of the hippocampus?\", \"type\": \"fact\", \"statement\": \"The hippocampus is responsible for motor control.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"What is the Schwarzschild radius?\", \"type\": \"concept\", \"statement\": \"The Schwarzschild radius is the minimum distance at which an object must orbit the Earth to avoid being pulled into the atmosphere.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Does quantum entanglement allow for faster-than-light communication?\", \"type\": \"concept\", \"statement\": \"Quantum entanglement enables instantaneous communication over long distances.\", \"label\": \"REFUTES\"},\n",
        "\n",
        "    # Дискуссионные/философские\n",
        "    {\"question\": \"Can mathematics fully describe reality?\", \"type\": \"concept\", \"statement\": \"Mathematics is a complete and perfect language for describing all aspects of reality.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"Is morality absolute or relative?\", \"type\": \"concept\", \"statement\": \"Moral values are absolute and universally applicable.\", \"label\": \"NOT ENOUGH INFO\"},\n",
        "    {\"question\": \"Is time an absolute concept?\", \"type\": \"concept\", \"statement\": \"Time is absolute and independent of any observer.\", \"label\": \"REFUTES\"},\n",
        "    {\"question\": \"Can the universe be infinite?\", \"type\": \"concept\", \"statement\": \"The universe has a finite boundary.\", \"label\": \"NOT ENOUGH INFO\"}\n",
        "]\n",
        "\n",
        "# Shuffle the dataset\n",
        "random.shuffle(questions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TYUA4hXJZXuM"
      },
      "outputs": [],
      "source": [
        "# Тест T5\n",
        "question = \"What is the capital of France?\"\n",
        "input_text = f\"Question: {question}\\nAnswer briefly.\"\n",
        "t5_inputs = t5_tokenizer(input_text, return_tensors=\"pt\").to(device) # Move t5_inputs to the device\n",
        "t5_outputs = t5_model.generate(**t5_inputs)\n",
        "print(\"T5 Output:\", t5_tokenizer.decode(t5_outputs[0], skip_special_tokens=True))\n",
        "\n",
        "# Тест RoBERTa\n",
        "statement = \"The capital of France is Paris.\"\n",
        "context = \"Paris is the capital and most populous city of France.\"\n",
        "roberta_inputs = roberta_tokenizer(f\"Statement: {statement} Context: {context}\", return_tensors=\"pt\").to(device) # Move roberta_inputs to the device\n",
        "roberta_outputs = roberta_model(**roberta_inputs)\n",
        "logits = roberta_outputs.logits\n",
        "print(\"RoBERTa Output:\", logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pe-x6FcBadMs"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install --upgrade --quiet transformers google-api-python-client\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration\n",
        "from googleapiclient.discovery import build\n",
        "from tqdm import tqdm\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Configure Device\n",
        "# ---------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Models Already Loaded\n",
        "# ---------------------------\n",
        "# Assuming models were loaded in a previous step\n",
        "# Variables to use:\n",
        "# - roberta_tokenizer\n",
        "# - roberta_model\n",
        "# - t5_tokenizer\n",
        "# - t5_model\n",
        "# - summarizer_pipeline\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Google Custom Search API\n",
        "# ---------------------------\n",
        "def retrieve_context_from_google(question, top_k=3):\n",
        "    \"\"\"\n",
        "    Use Google Custom Search API to retrieve top_k results for the given question.\n",
        "    Returns concatenated snippets of the search results.\n",
        "    \"\"\"\n",
        "    api_key = \"\"  # Replace with your actual API key\n",
        "    cse_id = \"\"  # Replace with your Custom Search Engine ID\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
        "\n",
        "    try:\n",
        "        result = service.cse().list(q=question, cx=cse_id, num=top_k).execute()\n",
        "        snippets = [item.get(\"snippet\", \"\") for item in result.get(\"items\", [])]\n",
        "        return \" \".join(snippets) if snippets else \"No relevant Google context found.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving context from Google: {e}\")\n",
        "        return \"No relevant Google context found.\"\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Helper Functions\n",
        "# ---------------------------\n",
        "def summarize_context(context, max_len=150, min_len=40):\n",
        "    \"\"\"\n",
        "    Summarizes the context text using BART. Adjust max_len/min_len as needed.\n",
        "    \"\"\"\n",
        "    if not context.strip():\n",
        "        return \"No context to summarize.\"\n",
        "    summarized = summarizer_pipeline(context, max_length=max_len, min_length=min_len, do_sample=False)\n",
        "    return summarized[0]['summary_text']\n",
        "\n",
        "def ask_if_context_needed(question):\n",
        "    \"\"\"\n",
        "    Use T5 to decide whether external context is required to answer the given question.\n",
        "    Returns:\n",
        "        - Boolean (True if context is needed, False otherwise)\n",
        "        - Raw response from the model (reasoning chain)\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You are a reasoning assistant. Decide if the question below requires external knowledge \"\n",
        "        \"like a search engine or is answerable by common knowledge and simple logic alone.\\n\\n\"\n",
        "        \"INSTRUCTIONS:\\n\"\n",
        "        \"1. Think step by step through the question.\\n\"\n",
        "        \"2. If you are NOT 100% certain you can answer without external knowledge, say YES.\\n\"\n",
        "        \"3. If you are certain it is trivial or well-known, say NO.\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Let's reason step by step and conclude with either 'YES' or 'NO':\"\n",
        "    )\n",
        "\n",
        "    inputs = t5_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "    outputs = t5_model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n",
        "    response = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Decide based on the response\n",
        "    if \"YES\" in response.upper():\n",
        "        return True, response\n",
        "    elif \"NO\" in response.upper():\n",
        "        return False, response\n",
        "    else:\n",
        "        # Default to YES if ambiguous\n",
        "        return True, response\n",
        "\n",
        "\n",
        "def classify_with_roberta(statement, context):\n",
        "    \"\"\"\n",
        "    Classify a statement as SUPPORTS, REFUTES, or NOT ENOUGH INFO based on context.\n",
        "    \"\"\"\n",
        "    prompt = f\"Statement: {statement}\\nContext: {context}\\nClassify into SUPPORTS, REFUTES, or NOT ENOUGH INFO.\"\n",
        "    inputs = roberta_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    outputs = roberta_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    confidence, label_idx = torch.max(probabilities, dim=1)\n",
        "    labels = [\"REFUTES\", \"NOT ENOUGH INFO\", \"SUPPORTS\"]\n",
        "    return labels[label_idx.item()], float(confidence.item())\n",
        "\n",
        "def generate_with_t5(question, context):\n",
        "    \"\"\"\n",
        "    Generate an answer with T5 for a given question and context. If you aren't confident, say \"I don't know.\"\n",
        "    \"\"\"\n",
        "    input_text = f\"Context: {context}\\nQuestion: {question}\\nAnswer briefly.\"\n",
        "    inputs = t5_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    outputs = t5_model.generate(inputs[\"input_ids\"], max_length=64, num_beams=4)\n",
        "    return t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Google Sheets Setup\n",
        "# ---------------------------\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "sheet = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1VDOKkz09sVWTBGtcD9Ne654o2OtumEyIqBIOELGBWW0/edit?gid=0#gid=0\").sheet1\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Example Dataset (50 Questions)\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "def self_assess_with_t5(question, context, generated_answer):\n",
        "    \"\"\"\n",
        "    Use T5 to self-assess confidence in its generated answer.\n",
        "    Returns a score from 1 to 100.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You answered the following question. Assess your confidence in the answer on a scale from 1 to 5.\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Context: {context}\\n\"\n",
        "        f\"Your Answer: {generated_answer}\\n\"\n",
        "        \"Confidence (1-5):\"\n",
        "    )\n",
        "    inputs = t5_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "    outputs = t5_model.generate(inputs[\"input_ids\"], max_length=20, num_beams=4, early_stopping=True)\n",
        "    response = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract numerical confidence\n",
        "    try:\n",
        "        confidence_score = int(\"\".join(filter(str.isdigit, response)))\n",
        "        return confidence_score if 1 <= confidence_score <= 5 else 1\n",
        "    except ValueError:\n",
        "        return 1\n",
        "\n",
        "\n",
        "def roberta_self_assess(statement, context):\n",
        "    \"\"\"\n",
        "    Use RoBERTa to self-assess confidence in its classification result.\n",
        "    Returns a self-assessed confidence score from 1 to 100.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"Statement: {statement}\\n\"\n",
        "        f\"Context: {context}\\n\"\n",
        "        \"I just classified this statement. Now, self-assess your confidence in your own classification.\\n\"\n",
        "        \"Provide a confidence score on a scale from 1 to 5 based on how well the context supports your decision:\"\n",
        "    )\n",
        "    inputs = roberta_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    outputs = roberta_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Extract confidence directly from logits for simplicity\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    max_prob = probabilities.max().item()\n",
        "\n",
        "    # Scale the max_prob (0-1) to a confidence score (1-5)\n",
        "    self_assessment_score = int(max_prob * 5)\n",
        "    return self_assessment_score\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_t5_confidence(question, context):\n",
        "    \"\"\"\n",
        "    Calculate T5 confidence for the generated answer based on output logits.\n",
        "    Returns the generated answer and confidence score.\n",
        "    \"\"\"\n",
        "    input_text = f\"Context: {context}\\nQuestion: {question}\\nAnswer briefly.\"\n",
        "    inputs = t5_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Generate output while retaining logits\n",
        "    outputs = t5_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=64,\n",
        "        num_beams=4,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True\n",
        "    )\n",
        "\n",
        "    generated_ids = outputs.sequences[0]\n",
        "    token_scores = outputs.scores  # List of logits for each step in the output sequence\n",
        "\n",
        "    # Decode the answer\n",
        "    generated_answer = t5_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Safeguard against mismatched lengths\n",
        "    token_probs = []\n",
        "    for step, logits in enumerate(token_scores[:len(generated_ids) - 1]):  # Ensure alignment\n",
        "        token_id = generated_ids[step + 1]  # Offset by 1 because scores are for the next token\n",
        "        token_prob = F.softmax(logits, dim=-1)[0, token_id].item()\n",
        "        token_probs.append(token_prob)\n",
        "\n",
        "    # Calculate the average confidence over all tokens\n",
        "    avg_confidence = sum(token_probs) / len(token_probs) if token_probs else 0.0\n",
        "    return generated_answer, avg_confidence\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Main Pipeline\n",
        "# ---------------------------\n",
        "results = []\n",
        "\n",
        "for q in tqdm(questions, desc=\"Processing Questions\"):\n",
        "    question = q[\"question\"]\n",
        "    statement = q[\"statement\"]\n",
        "    original_label = q[\"label\"]\n",
        "\n",
        "    if original_label == \"NOT ENOUGH INFO\":\n",
        "      context = \"\"\n",
        "      summarized_context = \"\"\n",
        "    else:\n",
        "      context = retrieve_context_from_google(question)\n",
        "      summarized_context = summarize_context(context)\n",
        "\n",
        "    # Step 2: Ask if context is needed for text generation (T5)\n",
        "    needs_context, reasoning = ask_if_context_needed(question)\n",
        "\n",
        "    if not needs_context:\n",
        "        # If T5 doesn't need context, ignore retrieved context for answer generation\n",
        "        t5_context = \"No external context used.\"\n",
        "        t5_summarized_context = \"No summary (context not needed).\"\n",
        "    else:\n",
        "        t5_context = context\n",
        "        t5_summarized_context = summarized_context\n",
        "\n",
        "    # Step 3: Generate answer with T5\n",
        "    generated_answer, t5_confidence = get_t5_confidence(question, t5_summarized_context)\n",
        "\n",
        "    # Step 4: Perform self-assessment with T5\n",
        "    t5_self_assessment = self_assess_with_t5(question, t5_summarized_context, generated_answer)\n",
        "\n",
        "    # Step 5: Classify the statement with RoBERTa\n",
        "    label, roberta_confidence = classify_with_roberta(statement, summarized_context)\n",
        "\n",
        "    roberta_self_assessment = roberta_self_assess(statement, summarized_context)\n",
        "\n",
        "\n",
        "    # Step 6: Append results\n",
        "    results.append([\n",
        "        question,\n",
        "        statement,\n",
        "        original_label,  # Original label from dataset\n",
        "        needs_context,\n",
        "        reasoning,\n",
        "        t5_context,\n",
        "        t5_summarized_context,\n",
        "        context,\n",
        "        summarized_context,\n",
        "        generated_answer,\n",
        "        t5_confidence,  # T5's confidence in its answer\n",
        "        t5_self_assessment,  # T5's self-assessment score\n",
        "        label,\n",
        "        roberta_confidence,\n",
        "        roberta_self_assessment  # Self-assessment from RoBERTa\n",
        "    ])\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Write to Google Sheet\n",
        "# ---------------------------\n",
        "headers = [\n",
        "    \"Question\",\n",
        "    \"Statement\",\n",
        "    \"Original Label\",\n",
        "    \"Needs Context?\",\n",
        "    \"Context Decision Reasoning\",\n",
        "    \"T5 Context\",\n",
        "    \"T5 Summarized Context\",\n",
        "    \"Roberta Context\",\n",
        "    \"Roberta Summarized Context\",\n",
        "    \"T5 Generated Answer\",\n",
        "    \"T5 Confidence\",\n",
        "    \"T5 Self-Assessment\",  # New column for self-assessment score\n",
        "    \"Classification\",\n",
        "    \"Roberta Confidence\",\n",
        "    \"Roberta Self-Assessment\"\n",
        "]\n",
        "\n",
        "sheet.clear()\n",
        "sheet.append_row(headers)\n",
        "\n",
        "for row in results:\n",
        "    sheet.append_row(row)\n",
        "\n",
        "print(\"Results written to Google Sheet!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BT9QZI9JfXy3"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install --quiet matplotlib pandas gspread oauth2client seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Authenticate and Load Data\n",
        "# ---------------------------\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Replace with your Google Sheet URL\n",
        "sheet_url = 'https://docs.google.com/spreadsheets/d/1VDOKkz09sVWTBGtcD9Ne654o2OtumEyIqBIOELGBWW0/edit?gid=0#gid=0'\n",
        "sheet = gc.open_by_url(sheet_url).sheet1\n",
        "\n",
        "# Load data into a Pandas DataFrame\n",
        "data = pd.DataFrame(sheet.get_all_records())\n",
        "\n",
        "# Helper function to clean data\n",
        "def clean_data(df, columns):\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    return df.dropna(subset=columns)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Visualizations\n",
        "# ---------------------------\n",
        "\n",
        "# Visualization 1: Distribution of Classification Labels\n",
        "plt.figure(figsize=(8, 6))\n",
        "data[\"Classification\"].value_counts().plot(kind=\"bar\", color=[\"skyblue\", \"salmon\", \"lime\"])\n",
        "plt.title(\"Distribution of Classification Labels\", fontsize=14)\n",
        "plt.xlabel(\"Classification Labels\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: T5 Self-Assessment Score Distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "data[\"T5 Self-Assessment\"].replace(\"Invalid\", 0, inplace=True)\n",
        "data[\"T5 Self-Assessment\"] = pd.to_numeric(data[\"T5 Self-Assessment\"], errors=\"coerce\")\n",
        "data[\"T5 Self-Assessment\"].plot(kind=\"hist\", bins=10, color=\"orange\", alpha=0.7)\n",
        "plt.title(\"Distribution of T5 Self-Assessment Scores\", fontsize=14)\n",
        "plt.xlabel(\"Self-Assessment Score\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 3: Context Requirement Breakdown\n",
        "if \"Needs Context?\" in data.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    context_needs = data[\"Needs Context?\"].value_counts()\n",
        "    context_needs.plot(kind=\"pie\", autopct=\"%1.1f%%\", startangle=140, colors=[\"gold\", \"lightgreen\"])\n",
        "    plt.title(\"Proportion of Questions Requiring Context\", fontsize=14)\n",
        "    plt.ylabel(\"\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualization 4: T5 Confidence vs. T5 Self-Assessment\n",
        "data = clean_data(data, [\"T5 Confidence\", \"T5 Self-Assessment\"])\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x=data[\"T5 Confidence\"],\n",
        "    y=data[\"T5 Self-Assessment\"],\n",
        "    label=\"T5\",\n",
        "    color=\"blue\",\n",
        "    alpha=0.7,\n",
        "    edgecolor=\"k\"\n",
        ")\n",
        "sns.regplot(\n",
        "    x=data[\"T5 Confidence\"],\n",
        "    y=data[\"T5 Self-Assessment\"],\n",
        "    scatter=False,\n",
        "    color=\"blue\",\n",
        "    line_kws={\"linestyle\": \"dashed\"}\n",
        ")\n",
        "plt.title(\"T5 Confidence vs. T5 Self-Assessment\", fontsize=14)\n",
        "plt.xlabel(\"T5 Confidence (0-1)\", fontsize=12)\n",
        "plt.ylabel(\"T5 Self-Assessment Score\", fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 5: RoBERTa Confidence vs. RoBERTa Self-Assessment\n",
        "data = clean_data(data, [\"Roberta Confidence\", \"Roberta Self-Assessment\"])\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x=data[\"Roberta Confidence\"],\n",
        "    y=data[\"Roberta Self-Assessment\"],\n",
        "    label=\"RoBERTa\",\n",
        "    color=\"red\",\n",
        "    alpha=0.7,\n",
        "    edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "# Добавляем горизонтальную линию\n",
        "plt.axhline(y=4, color=\"red\", linestyle=\"dashed\", linewidth=1.5, alpha=0.8)\n",
        "\n",
        "# Настройки графика\n",
        "plt.title(\"RoBERTa Confidence vs. RoBERTa Self-Assessment\", fontsize=14)\n",
        "plt.xlabel(\"RoBERTa Confidence (0-1)\", fontsize=12)\n",
        "plt.ylabel(\"RoBERTa Self-Assessment Score\", fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Отображение\n",
        "plt.show()\n",
        "\n",
        "# Visualization 6: Comparison of T5 and RoBERTa Confidence vs. Self-Assessment\n",
        "data = clean_data(data, [\"T5 Confidence\", \"T5 Self-Assessment\", \"Roberta Confidence\", \"Roberta Self-Assessment\"])\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(\n",
        "    x=data[\"T5 Confidence\"],\n",
        "    y=data[\"T5 Self-Assessment\"],\n",
        "    label=\"T5\",\n",
        "    color=\"blue\",\n",
        "    alpha=0.7\n",
        ")\n",
        "sns.scatterplot(\n",
        "    x=data[\"Roberta Confidence\"],\n",
        "    y=data[\"Roberta Self-Assessment\"],\n",
        "    label=\"RoBERTa\",\n",
        "    color=\"green\",\n",
        "    alpha=0.7\n",
        ")\n",
        "sns.regplot(\n",
        "    x=data[\"T5 Confidence\"],\n",
        "    y=data[\"T5 Self-Assessment\"],\n",
        "    scatter=False,\n",
        "    color=\"blue\",\n",
        "    line_kws={\"linestyle\": \"dashed\"}\n",
        ")\n",
        "sns.regplot(\n",
        "    x=data[\"Roberta Confidence\"],\n",
        "    y=data[\"Roberta Self-Assessment\"],\n",
        "    scatter=False,\n",
        "    color=\"green\",\n",
        "    line_kws={\"linestyle\": \"dashed\"}\n",
        ")\n",
        "plt.title(\"Comparison of T5 and RoBERTa: Confidence vs. Self-Assessment\", fontsize=16, weight=\"bold\")\n",
        "plt.xlabel(\"Confidence (0-1)\", fontsize=14)\n",
        "plt.ylabel(\"Self-Assessment Score\", fontsize=14)\n",
        "plt.legend(title=\"Model\", fontsize=12, loc=\"upper left\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rCqusfivff8s"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install --quiet matplotlib pandas gspread oauth2client seaborn scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Authenticate and Load Data\n",
        "# ---------------------------\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Replace with your Google Sheet URL\n",
        "sheet = gc.open_by_url(sheet_url).sheet1\n",
        "\n",
        "# Load data into a Pandas DataFrame\n",
        "data = pd.DataFrame(sheet.get_all_records())\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Data Preparation\n",
        "# ---------------------------\n",
        "# Ensure numeric conversion where needed\n",
        "data[\"Roberta Confidence\"] = pd.to_numeric(data[\"Roberta Confidence\"], errors=\"coerce\")\n",
        "data = data.dropna(subset=[\"Classification\", \"Original Label\"])\n",
        "\n",
        "# Map labels to numerical values for metrics calculation\n",
        "label_mapping = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT ENOUGH INFO\": 2}\n",
        "data[\"Predicted\"] = data[\"Classification\"].map(label_mapping)\n",
        "data[\"Actual\"] = data[\"Original Label\"].map(label_mapping)\n",
        "\n",
        "# Drop rows with unmapped labels\n",
        "filtered_data = data.dropna(subset=[\"Predicted\", \"Actual\"])\n",
        "\n",
        "# Extract predictions and ground truth\n",
        "predictions = filtered_data[\"Predicted\"].astype(int)\n",
        "ground_truth = filtered_data[\"Actual\"].astype(int)\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Visualizations\n",
        "# ---------------------------\n",
        "\n",
        "# Visualization 1: Confusion Matrix\n",
        "conf_matrix = confusion_matrix(ground_truth, predictions, labels=[0, 1, 2])\n",
        "ConfusionMatrixDisplay(conf_matrix, display_labels=label_mapping.keys()).plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix: RoBERTa Predictions vs. Ground Truth\", fontsize=14, weight=\"bold\")\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Classification Report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(ground_truth, predictions, target_names=label_mapping.keys()))\n",
        "\n",
        "# Visualization 3: Accuracy per Class\n",
        "class_counts = filtered_data.groupby(\"Original Label\").size()\n",
        "accurate_counts = filtered_data[filtered_data[\"Predicted\"] == filtered_data[\"Actual\"]].groupby(\"Original Label\").size()\n",
        "\n",
        "accuracy_per_class = (accurate_counts / class_counts * 100).reindex(label_mapping.keys(), fill_value=0)\n",
        "plt.figure(figsize=(8, 6))\n",
        "accuracy_per_class.plot(kind=\"bar\", color=[\"skyblue\", \"salmon\", \"lime\"], alpha=0.8)\n",
        "plt.title(\"Accuracy per Class\", fontsize=14, weight=\"bold\")\n",
        "plt.xlabel(\"Class\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Visualization 4: Confidence Distribution for Correct/Incorrect Predictions\n",
        "filtered_data[\"Correct\"] = filtered_data[\"Predicted\"] == filtered_data[\"Actual\"]\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=filtered_data, x=\"Roberta Confidence\", hue=\"Correct\", kde=True, palette={True: \"green\", False: \"red\"}, alpha=0.6)\n",
        "plt.title(\"Confidence Distribution: Correct vs. Incorrect Predictions\", fontsize=14, weight=\"bold\")\n",
        "plt.xlabel(\"Confidence (0-1)\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Visualization 5: Distribution of Dataset Labels\n",
        "plt.figure(figsize=(8, 6))\n",
        "data[\"Original Label\"].value_counts().plot(kind=\"bar\", color=[\"skyblue\", \"salmon\", \"lime\"], alpha=0.8)\n",
        "plt.title(\"Distribution of Dataset Labels\", fontsize=14, weight=\"bold\")\n",
        "plt.xlabel(\"Labels\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}